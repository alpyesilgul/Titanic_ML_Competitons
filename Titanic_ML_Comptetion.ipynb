{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic_ML_Comptetion.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNz8Lr5WS15MhQpoc5mk4cm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alpyesilgul/Titanic_ML_Competitons/blob/main/Titanic_ML_Comptetion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUpCUk0k-yqG"
      },
      "source": [
        "**Merhaba,**\r\n",
        "ilgili kaynak ve için bir çok ingilizce kaynak olmasından dolayı yeni başlayan arkadaşlar için giriş seviyesinde\r\n",
        "*öğretici bir türkçe repositoriesdir*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGhJemCP-h7n"
      },
      "source": [
        "**Kaggle**, bir çok data scientist ve ML projeleri ile ödüllü yarışmaların düzenlendiği bir platformdur. Ücretsiz olarak [kayıt](https:///www.kaggle.com/account/login?phase=startRegisterTab&returnUrl=%2F) olabiliceğimiz ML ve Data Scientist ile ilgilenen arkadaşlar için oldukça eğitici bir platformdur. Amacım meraklı arkadaşlar için bir Türkçe kaynak oluşturmaktır."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4VXyLw_8HWF"
      },
      "source": [
        "Kaggle kendi bünyesinde bulunan bulunun kernel ile birlikte yarışmlarda oluşturduğumuz ağları CoLab de olduğu gibi (bulut tabanlı) eğitmek, eğitilen modeller ile predictionları kaydederken sisteme kaydetmektir. Sistem veya ilgili birimler tahminlere göre puanlama vererek katılan herkesin olduğu bir sıralama sunmaktadır. Titanic projesinde, tradejik bir kaza olan Titanic yolcularının cinsiyet, bilet türü, bilet fiyatı, kabin türü, yaş vb. bilgileri ile hayatta kalıp kalmadığının olduğu bir datasetimiz mevcuttur. Bu bilgiler ile düşünebiliceğiniz gibi test verimizde yukarıda belirtilen veriler ile yolcunun hayatta kalıp kalmadığını tahmin etmeye çalışacağız."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtU6cr9rCCGt"
      },
      "source": [
        "#Öncelikle dosya pathlerini ayarlayalım:\r\n",
        "train_path = \"src/train.csv\"\r\n",
        "test_path = \"src/test.csv\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8qnssMIC3xS"
      },
      "source": [
        "#CSV dosyalarını düzenlemek için pandas kütüphanesini çağıralım  \r\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um8ZiqcvDF3X"
      },
      "source": [
        "train_df = pd.read_csv(train_path)\r\n",
        "test_df = pd.read_csv(test_path)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "xXoZHzdMDR7Q",
        "outputId": "f762927f-aed0-416d-bec1-202d71c7570f"
      },
      "source": [
        "#Headerlarımıza bir göz atalım\r\n",
        "train_df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "3            4         1       1  ...  53.1000  C123         S\n",
              "4            5         0       3  ...   8.0500   NaN         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ki9RZySDbq-",
        "outputId": "23c56a7d-5321-4fa3-d5ff-ed1f66a58fcd"
      },
      "source": [
        "#Öncelikle veri setimizde olan boş kısımlara bakalım\r\n",
        "train_df.isnull().sum()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age            177\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             0\n",
              "Cabin          687\n",
              "Embarked         2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qTZGoJ1D98c",
        "outputId": "1cb0715a-f233-4517-d8a9-7be6bd919a6d"
      },
      "source": [
        "test_df.isnull().sum()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age             86\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             1\n",
              "Cabin          327\n",
              "Embarked         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGxPp2n7ELLN"
      },
      "source": [
        "#Veri setimizde eksik kısımların  yanı sıra eğitim sırasında gereksiz görebileceğimiz kısımlarda bulunmakta. Bunun preprocess adında bir\r\n",
        "#fonksiyon oluşturalım veri setimizi düzenleyelim.\r\n",
        "def preprocess(data):\r\n",
        "    data = data.drop(['Name', 'Ticket', 'Cabin'], axis=1) #Gereksiz headerları verilerle atıyoruz.\r\n",
        "    data[['Age']] = data[['Age']].fillna(value = data[['Age']].mean()) # Boş kısımlara sütunun ortalaması ile doldurduk.\r\n",
        "    data[['Fare']] = data[['Fare']].fillna(value = data[['Fare']].mean()) # yukarıdaki ile aynı işlem.\r\n",
        "    data[['Embarked']] = data[['Embarked']].fillna(value = data['Embarked'].value_counts().idxmax())# En çok tekrar edeni boş kısımlara doldurduk.\r\n",
        "    \r\n",
        "    data['Sex'] = data['Sex'].map({'female':1, 'male':0}).astype(int) # Burda kadın için 1 erkek için 0 değerlerini değiştirdik. \r\n",
        "    \r\n",
        "    embarked_onehot = pd.get_dummies(data['Embarked'], prefix='Embarked') # Tüm sütunu one_hot matrisine çeviriyoruz.\r\n",
        "    data = data.drop(['Embarked'], axis=1) # one_hot matrisine çevrilen sütünu siliyoruz.\r\n",
        "    data = data.join(embarked_onehot)\r\n",
        "    return data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7uvTzpxGXI5"
      },
      "source": [
        "# Model için pipeline oluşturduğumuza göre bunu verilere uygulayalım.\r\n",
        "train_data = preprocess(train_df)\r\n",
        "test_data = preprocess(test_df)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ3Vya3dHDpW"
      },
      "source": [
        "# Temizlenmiş veriler şuan tamamen sayısallaştırıldı, boşlukları doldurulmuş oldu. X, Y haritalanmasını belirleyelim.\r\n",
        "x_train = train_data.drop(['Survived'], axis=1).values.astype(float)\r\n",
        "y_train = train_data['Survived'].values"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_CM1pQhHk3P"
      },
      "source": [
        "# Datadan verim alabilmek için tüm datayı standardize edelim.\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "scaler = StandardScaler()\r\n",
        "X = scaler.fit_transform(x_train)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiT7QDE_IMST"
      },
      "source": [
        "Yukarıda hücrede uygulanan standardizasyon için daha detaylı bilgiye [buradan](https://towardsdatascience.com/what-and-why-behind-fit-transform-vs-transform-in-scikit-learn-78f915cf96fe) ulaşabilirsiniz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKmuChzyIJLA"
      },
      "source": [
        "# Verilerimiz tamamen oluşturduğumuza göre modele geçebiliriz.\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHBwzzuLJFf5"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Dense(32, input_dim = X.shape[1], activation='relu'))\r\n",
        "model.add(Dense(16,activation='relu'))\r\n",
        "model.add(Dense(8, activation='relu'))\r\n",
        "model.add(Dense(4,activation='relu'))\r\n",
        "model.add(Dense(2,activation='relu'))\r\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StxoQrj-JJf9"
      },
      "source": [
        "# Model için doğru optimizasyon için alttaki hücre hyperparametreler değiştirilerek tekrarlı bir şekilde değerlendirilebilir.\r\n",
        "import tensorflow as tf\r\n",
        "from keras import backend as K "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swyRrxgJJiFA"
      },
      "source": [
        "K.clear_session()\r\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=.001)\r\n",
        "loss = tf.keras.losses.MeanSquaredError()\r\n",
        "batch = 64\r\n",
        "epochs = 900\r\n",
        "steps = 13\r\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\r\n",
        "history = model.fit(X,y_train, batch_size=batch, epochs=epochs, shuffle = False, steps_per_epoch=steps, verbose=0)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw6nLdJ7Joyj",
        "outputId": "659006ed-86ad-4db3-c71f-d04872741ace"
      },
      "source": [
        "# Modelin performansını aşağıdaki hücre ile öğrenebiliriz.\r\n",
        "history.history['acc'][899]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9504232406616211"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY9J7ZwCJ3oH"
      },
      "source": [
        "#900 epoch ile %95 doğruluk başlangıç için ideal diyebiliriz."
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsrlV-lQK5ox"
      },
      "source": [
        "#Şimdi de gelin modelimiz ile test edelim.\r\n",
        "X_test = scaler.fit_transform(test_data)\r\n",
        "y_test_df = pd.read_csv('src/gender_submission.csv')\r\n",
        "Y_test = y_test_df['Survived'].values.astype(int)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jAzEN7xLFmj",
        "outputId": "e5500158-a1cb-48a4-806b-4decc87c1a62"
      },
      "source": [
        "model.evaluate(X_test,Y_test,batch_size=32)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 2ms/step - loss: 0.1490 - acc: 0.8158\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.14897489547729492, 0.8157894611358643]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7n0iubfLcJR"
      },
      "source": [
        "#Test için ise modelimiz %85 doğruluk oranı verdi. Gayet güzel :)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1fJ1GpNLmIr"
      },
      "source": [
        "#Son olarak da Kaggle için modelimiz tahmin skorlarını bir CSV dosyasına aktarmamız gerekiyor.\r\n",
        "prediction = model.predict(X_test)\r\n",
        "binary_prediction = []\r\n",
        "for i in range(len(prediction)):\r\n",
        "    if prediction[i] < .5:\r\n",
        "        binary_prediction.append(0)\r\n",
        "    else:\r\n",
        "        binary_prediction.append(1)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQY3GJQJL5EU"
      },
      "source": [
        "#PassengerID ile birlikte tahminlerimiz dosyaya yazıyoruz\r\n",
        "pas_num = y_test_df['PassengerId'].values.astype(int)\r\n",
        "sub = pd.DataFrame({'PassengerId' : pas_num,\r\n",
        "                   'Survived': binary_prediction})\r\n",
        "sub.to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF_7K4JeMLZv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR3KexYXMNRL"
      },
      "source": [
        "**TEBRİKLER!** İlk kaggle comptetionımızı tamamladık. Elimden geldiğince başlangıç ve orta seviyelerde ML projeleri paylaşmaya çalışacağım :)\r\n",
        " "
      ]
    }
  ]
}